{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "(train_x,train_y),(test_x,test_y)=fashion_mnist.load_data()\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   1   0   0   0   0  41 188 103  54  48  43  87 168\n",
      "  133  16   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   1   0   0   0  49 136 219 216 228 236 255 255 255 255 217\n",
      "  215 254 231 160  45   0   0   0   0   0]\n",
      " [  0   0   0   0   0  14 176 222 224 212 203 198 196 200 215 204 202 201\n",
      "  201 201 209 218 224 164   0   0   0   0]\n",
      " [  0   0   0   0   0 188 219 200 198 202 198 199 199 201 196 198 198 200\n",
      "  200 200 200 201 200 225  41   0   0   0]\n",
      " [  0   0   0   0  51 219 199 203 203 212 238 248 250 245 249 246 247 252\n",
      "  248 235 207 203 203 222 140   0   0   0]\n",
      " [  0   0   0   0 116 226 206 204 207 204 101  75  47  73  48  50  45  51\n",
      "   63 113 222 202 206 220 224   0   0   0]\n",
      " [  0   0   0   0 200 222 209 203 215 200   0  70  98   0 103  59  68  71\n",
      "   49   0 219 206 214 210 250  38   0   0]\n",
      " [  0   0   0   0 247 218 212 210 215 214   0 254 243 139 255 174 251 255\n",
      "  205   0 215 217 214 208 220  95   0   0]\n",
      " [  0   0   0  45 226 214 214 215 224 205   0  42  35  60  16  17  12  13\n",
      "   70   0 189 216 212 206 212 156   0   0]\n",
      " [  0   0   0 164 235 214 211 220 216 201  52  71  89  94  83  78  70  76\n",
      "   92  87 206 207 222 213 219 208   0   0]\n",
      " [  0   0   0 106 187 223 237 248 211 198 252 250 248 245 248 252 253 250\n",
      "  252 239 201 212 225 215 193 113   0   0]\n",
      " [  0   0   0   0   0  17  54 159 222 193 208 192 197 200 200 200 200 201\n",
      "  203 195 210 165   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  47 225 192 214 203 206 204 204 205 206 204\n",
      "  212 197 218 107   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   6   0  46 212 195 212 202 206 205 204 205 206 204\n",
      "  212 200 218  91   0   3   1   0   0   0]\n",
      " [  0   0   0   0   0   1   0  11 197 199 205 202 205 206 204 205 207 204\n",
      "  205 205 218  77   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   3   0   2 191 198 201 205 206 205 205 206 209 206\n",
      "  199 209 219  74   0   5   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 188 197 200 207 207 204 207 207 210 208\n",
      "  198 207 221  72   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   2   0   0 215 198 203 206 208 205 207 207 210 208\n",
      "  200 202 222  75   0   4   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 212 198 209 206 209 206 208 207 211 206\n",
      "  205 198 221  80   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 201 205 208 207 205 211 205 210 210\n",
      "  209 195 221  96   0   3   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 202 201 205 209 207 205 213 206 210 209\n",
      "  210 194 217 105   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 204 204 205 208 207 205 215 207 210 208\n",
      "  211 193 213 115   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 204 207 207 208 206 206 215 210 210 207\n",
      "  212 195 210 118   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 208 208 208 204 207 212 212 210 207\n",
      "  211 196 207 121   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 198 210 207 208 206 209 213 212 211 207\n",
      "  210 197 207 124   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 172 210 203 201 199 204 207 205 204 201\n",
      "  205 197 206 127   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 188 221 214 234 236 238 244 244 244 240\n",
      "  243 214 224 162   0   2   0   0   0   0]\n",
      " [  0   0   0   0   0   1   0   0 139 146 130 135 135 137 125 124 125 121\n",
      "  119 114 130  76   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(train_x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47040000, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x=train_x.reshape(-1,1)\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 16s 331us/sample - loss: 1.1677 - accuracy: 0.7843- loss: 1.1704 - accuracy: 0.\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 13s 268us/sample - loss: 0.7506 - accuracy: 0.8078\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 12s 258us/sample - loss: 0.7029 - accuracy: 0.8123\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 12s 256us/sample - loss: 0.6690 - accuracy: 0.8186\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.6432 - accuracy: 0.8238\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 12s 257us/sample - loss: 0.6277 - accuracy: 0.8273-\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 12s 250us/sample - loss: 0.6099 - accuracy: 0.8322\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 12s 250us/sample - loss: 0.5965 - accuracy: 0.8331\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 12s 255us/sample - loss: 0.5838 - accuracy: 0.8379\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.5723 - accuracy: 0.8385\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 12s 249us/sample - loss: 0.5669 - accuracy: 0.8403\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 12s 244us/sample - loss: 0.5591 - accuracy: 0.8432\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 12s 248us/sample - loss: 0.5558 - accuracy: 0.8408\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 12s 247us/sample - loss: 0.5477 - accuracy: 0.8441\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 12s 259us/sample - loss: 0.5436 - accuracy: 0.8439\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.5437 - accuracy: 0.8431\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 12s 246us/sample - loss: 0.5393 - accuracy: 0.8457\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 12s 247us/sample - loss: 0.5342 - accuracy: 0.8458\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 12s 253us/sample - loss: 0.5315 - accuracy: 0.8451\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 14s 297us/sample - loss: 0.5258 - accuracy: 0.8468 - val_loss: 0.5407 - val_accuracy: 0.8396\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 12s 243us/sample - loss: 0.5259 - accuracy: 0.8466\n",
      "Epoch 22/100\n",
      "48000/48000 [==============================] - 12s 245us/sample - loss: 0.5248 - accuracy: 0.8469\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 13s 261us/sample - loss: 0.5251 - accuracy: 0.8468\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 12s 242us/sample - loss: 0.5209 - accuracy: 0.8458\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 12s 245us/sample - loss: 0.5167 - accuracy: 0.8497\n",
      "Epoch 26/100\n",
      "48000/48000 [==============================] - 12s 250us/sample - loss: 0.5164 - accuracy: 0.8461\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 12s 254us/sample - loss: 0.5143 - accuracy: 0.8497\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - ETA: 0s - loss: 0.5112 - accuracy: 0.85 - 12s 250us/sample - loss: 0.5109 - accuracy: 0.8504\n",
      "Epoch 29/100\n",
      "48000/48000 [==============================] - 12s 258us/sample - loss: 0.5105 - accuracy: 0.8508\n",
      "Epoch 30/100\n",
      "48000/48000 [==============================] - 12s 242us/sample - loss: 0.5128 - accuracy: 0.8478\n",
      "Epoch 31/100\n",
      "48000/48000 [==============================] - 13s 268us/sample - loss: 0.5079 - accuracy: 0.8510\n",
      "Epoch 32/100\n",
      "48000/48000 [==============================] - 13s 277us/sample - loss: 0.5078 - accuracy: 0.8508- loss: 0.5\n",
      "Epoch 33/100\n",
      "48000/48000 [==============================] - 13s 280us/sample - loss: 0.5061 - accuracy: 0.8494\n",
      "Epoch 34/100\n",
      "48000/48000 [==============================] - 13s 270us/sample - loss: 0.5049 - accuracy: 0.8499- loss: 0.5031 - accuracy: 0. - ETA: 0s - loss: 0.5032 - accuracy:  - ETA: 0s - loss: 0.5039 - \n",
      "Epoch 35/100\n",
      "48000/48000 [==============================] - 13s 265us/sample - loss: 0.5039 - accuracy: 0.8500\n",
      "Epoch 36/100\n",
      "48000/48000 [==============================] - 13s 276us/sample - loss: 0.4998 - accuracy: 0.8520\n",
      "Epoch 37/100\n",
      "48000/48000 [==============================] - 12s 251us/sample - loss: 0.5011 - accuracy: 0.8511-\n",
      "Epoch 38/100\n",
      "48000/48000 [==============================] - 12s 255us/sample - loss: 0.5001 - accuracy: 0.8505- ETA: 2s - los\n",
      "Epoch 39/100\n",
      "48000/48000 [==============================] - 13s 266us/sample - loss: 0.4987 - accuracy: 0.8512- loss: 0.4990 \n",
      "Epoch 40/100\n",
      "48000/48000 [==============================] - 16s 340us/sample - loss: 0.4993 - accuracy: 0.8504 - val_loss: 0.4977 - val_accuracy: 0.8516\n",
      "Epoch 41/100\n",
      "48000/48000 [==============================] - 12s 253us/sample - loss: 0.4984 - accuracy: 0.8522\n",
      "Epoch 42/100\n",
      "48000/48000 [==============================] - 12s 260us/sample - loss: 0.4985 - accuracy: 0.8520\n",
      "Epoch 43/100\n",
      "48000/48000 [==============================] - 12s 252us/sample - loss: 0.4988 - accuracy: 0.8505\n",
      "Epoch 44/100\n",
      "48000/48000 [==============================] - 13s 261us/sample - loss: 0.4940 - accuracy: 0.8508\n",
      "Epoch 45/100\n",
      "48000/48000 [==============================] - 13s 268us/sample - loss: 0.4949 - accuracy: 0.8524\n",
      "Epoch 46/100\n",
      "48000/48000 [==============================] - 12s 249us/sample - loss: 0.4934 - accuracy: 0.8518\n",
      "Epoch 47/100\n",
      "48000/48000 [==============================] - 12s 257us/sample - loss: 0.4922 - accuracy: 0.8544\n",
      "Epoch 48/100\n",
      "48000/48000 [==============================] - 12s 244us/sample - loss: 0.4933 - accuracy: 0.8522\n",
      "Epoch 49/100\n",
      "48000/48000 [==============================] - 12s 245us/sample - loss: 0.4931 - accuracy: 0.8510- loss: 0.4933 - accuracy\n",
      "Epoch 50/100\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.4919 - accuracy: 0.8539\n",
      "Epoch 51/100\n",
      "48000/48000 [==============================] - 14s 290us/sample - loss: 0.4890 - accuracy: 0.8533\n",
      "Epoch 52/100\n",
      "48000/48000 [==============================] - 12s 252us/sample - loss: 0.4889 - accuracy: 0.8540\n",
      "Epoch 53/100\n",
      "48000/48000 [==============================] - 12s 250us/sample - loss: 0.4900 - accuracy: 0.8523- loss: 0\n",
      "Epoch 54/100\n",
      "48000/48000 [==============================] - 12s 242us/sample - loss: 0.4860 - accuracy: 0.8530\n",
      "Epoch 55/100\n",
      "48000/48000 [==============================] - 12s 249us/sample - loss: 0.4870 - accuracy: 0.8533A: 0s - loss: 0\n",
      "Epoch 56/100\n",
      "48000/48000 [==============================] - 12s 245us/sample - loss: 0.4881 - accuracy: 0.8544\n",
      "Epoch 57/100\n",
      "48000/48000 [==============================] - 12s 241us/sample - loss: 0.4878 - accuracy: 0.8538- loss: 0.4892 - accura - ETA: 0s - loss: 0.4\n",
      "Epoch 58/100\n",
      "48000/48000 [==============================] - 12s 253us/sample - loss: 0.4870 - accuracy: 0.8522\n",
      "Epoch 59/100\n",
      "48000/48000 [==============================] - 12s 246us/sample - loss: 0.4857 - accuracy: 0.8551\n",
      "Epoch 60/100\n",
      "48000/48000 [==============================] - 13s 278us/sample - loss: 0.4861 - accuracy: 0.8534 - val_loss: 0.5151 - val_accuracy: 0.8463\n",
      "Epoch 61/100\n",
      "48000/48000 [==============================] - 12s 241us/sample - loss: 0.4839 - accuracy: 0.8528- loss: 0.4844 - accuracy: \n",
      "Epoch 62/100\n",
      "48000/48000 [==============================] - 13s 273us/sample - loss: 0.4868 - accuracy: 0.8539\n",
      "Epoch 63/100\n",
      "48000/48000 [==============================] - 12s 247us/sample - loss: 0.4876 - accuracy: 0.8531- loss: 0.4881 - accuracy: 0.85 - ETA: 0s - los\n",
      "Epoch 64/100\n",
      "48000/48000 [==============================] - 12s 246us/sample - loss: 0.4825 - accuracy: 0.8537\n",
      "Epoch 65/100\n",
      "48000/48000 [==============================] - 12s 241us/sample - loss: 0.4843 - accuracy: 0.8525- loss: 0.4826 \n",
      "Epoch 66/100\n",
      "48000/48000 [==============================] - 12s 244us/sample - loss: 0.4855 - accuracy: 0.8534\n",
      "Epoch 67/100\n",
      "48000/48000 [==============================] - 13s 267us/sample - loss: 0.4849 - accuracy: 0.8529\n",
      "Epoch 68/100\n",
      "48000/48000 [==============================] - 13s 273us/sample - loss: 0.4853 - accuracy: 0.8543\n",
      "Epoch 69/100\n",
      "48000/48000 [==============================] - 12s 257us/sample - loss: 0.4793 - accuracy: 0.8544\n",
      "Epoch 70/100\n",
      "48000/48000 [==============================] - 12s 246us/sample - loss: 0.4797 - accuracy: 0.8550- loss: 0.4800 - ac\n",
      "Epoch 71/100\n",
      "48000/48000 [==============================] - 13s 275us/sample - loss: 0.4849 - accuracy: 0.8534\n",
      "Epoch 72/100\n",
      "48000/48000 [==============================] - 14s 282us/sample - loss: 0.4803 - accuracy: 0.8557\n",
      "Epoch 73/100\n",
      "48000/48000 [==============================] - 15s 303us/sample - loss: 0.4785 - accuracy: 0.8551\n",
      "Epoch 74/100\n",
      "48000/48000 [==============================] - 14s 292us/sample - loss: 0.4814 - accuracy: 0.8537- loss: 0.481\n",
      "Epoch 75/100\n",
      "48000/48000 [==============================] - 13s 280us/sample - loss: 0.4808 - accuracy: 0.8543- l - ETA: 0s - loss: 0.4810 - accu\n",
      "Epoch 76/100\n",
      "48000/48000 [==============================] - 13s 270us/sample - loss: 0.4847 - accuracy: 0.8531\n",
      "Epoch 77/100\n",
      "48000/48000 [==============================] - 11s 229us/sample - loss: 0.4809 - accuracy: 0.8536\n",
      "Epoch 78/100\n",
      "48000/48000 [==============================] - 11s 232us/sample - loss: 0.4823 - accuracy: 0.8553\n",
      "Epoch 79/100\n",
      "48000/48000 [==============================] - 14s 285us/sample - loss: 0.4758 - accuracy: 0.8552- ETA: 0s - loss: 0.4761 - accuracy: 0.\n",
      "Epoch 80/100\n",
      "48000/48000 [==============================] - 13s 275us/sample - loss: 0.4807 - accuracy: 0.8540 - val_loss: 0.5028 - val_accuracy: 0.8446\n",
      "Epoch 81/100\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.4774 - accuracy: 0.8558\n",
      "Epoch 82/100\n",
      "48000/48000 [==============================] - 13s 268us/sample - loss: 0.4766 - accuracy: 0.8553\n",
      "Epoch 83/100\n",
      "48000/48000 [==============================] - 10s 211us/sample - loss: 0.4803 - accuracy: 0.8541\n",
      "Epoch 84/100\n",
      "48000/48000 [==============================] - 10s 213us/sample - loss: 0.4827 - accuracy: 0.8539\n",
      "Epoch 85/100\n",
      "48000/48000 [==============================] - 14s 284us/sample - loss: 0.4788 - accuracy: 0.8561\n",
      "Epoch 86/100\n",
      "48000/48000 [==============================] - 16s 336us/sample - loss: 0.4784 - accuracy: 0.8561\n",
      "Epoch 87/100\n",
      "48000/48000 [==============================] - 14s 291us/sample - loss: 0.4742 - accuracy: 0.8579\n",
      "Epoch 88/100\n",
      "48000/48000 [==============================] - 13s 264us/sample - loss: 0.4756 - accuracy: 0.8559\n",
      "Epoch 89/100\n",
      "48000/48000 [==============================] - 12s 260us/sample - loss: 0.4765 - accuracy: 0.8560\n",
      "Epoch 90/100\n",
      "48000/48000 [==============================] - 13s 277us/sample - loss: 0.4747 - accuracy: 0.8559- loss:\n",
      "Epoch 91/100\n",
      "48000/48000 [==============================] - 13s 278us/sample - loss: 0.4759 - accuracy: 0.8559\n",
      "Epoch 92/100\n",
      "48000/48000 [==============================] - 12s 254us/sample - loss: 0.4769 - accuracy: 0.8551\n",
      "Epoch 93/100\n",
      "48000/48000 [==============================] - 12s 249us/sample - loss: 0.4765 - accuracy: 0.8537\n",
      "Epoch 94/100\n",
      "48000/48000 [==============================] - 12s 248us/sample - loss: 0.4743 - accuracy: 0.8554\n",
      "Epoch 95/100\n",
      "48000/48000 [==============================] - 12s 254us/sample - loss: 0.4758 - accuracy: 0.8562\n",
      "Epoch 96/100\n",
      "48000/48000 [==============================] - 12s 250us/sample - loss: 0.4765 - accuracy: 0.8553\n",
      "Epoch 97/100\n",
      "48000/48000 [==============================] - 13s 274us/sample - loss: 0.4771 - accuracy: 0.8562- l - ETA: 0s - loss: 0.4766 - accuracy: 0. - ETA: 0s - loss: 0.4770  - ETA: 0s - loss: 0.4765 - accura\n",
      "Epoch 98/100\n",
      "48000/48000 [==============================] - 12s 253us/sample - loss: 0.4749 - accuracy: 0.8565\n",
      "Epoch 99/100\n",
      "48000/48000 [==============================] - 12s 259us/sample - loss: 0.4776 - accuracy: 0.8532\n",
      "Epoch 100/100\n",
      "48000/48000 [==============================] - 14s 295us/sample - loss: 0.4694 - accuracy: 0.8568 - val_loss: 0.4979 - val_accuracy: 0.8479\n",
      "<tensorflow.python.keras.callbacks.History object at 0x000001598592A708>\n"
     ]
    }
   ],
   "source": [
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(units=128,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2()))\n",
    "model.add(tf.keras.layers.Dense(units=50,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2()))\n",
    "model.add(tf.keras.layers.Dense(units=10,activation=\"softmax\"))\n",
    "model.compile(optimizer=\"adam\",loss=tf.keras.losses.sparse_categorical_crossentropy,metrics=[\"accuracy\"])\n",
    "train_x=train_x/255.0\n",
    "test_x=test_x/255.0\n",
    "train_history=model.fit(train_x,train_y,validation_split=0.2,validation_freq=20,batch_size=50,epochs=100)\n",
    "print(train_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
