{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n",
      "2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)\n",
    "print(tf.keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#常见模型类型是层的堆叠：如下\n",
    "model=tf.keras.Sequential()\n",
    "model.add(layers.Dense(units=32,activation=\"relu\"))\n",
    "model.add(layers.Dense(units=32,activation=\"relu\"))\n",
    "model.add(layers.Dense(units=10,activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.layers中网络配置：\n",
    "activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\n",
    "kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。\n",
    "kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(layers.Dense(units=32,kernel_initializer=tf.keras.initializers.glorot_normal))\n",
    "model.add(layers.Dense(units=32,kernel_regularizer=tf.keras.regularizers.l2(0.01)))\n",
    "model.add(layers.Dense(units=32,kernel_regularizer=tf.keras.regularizers.l1(0.01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential()\n",
    "model.add(layers.Dense(units=32,activation=\"relu\"))\n",
    "model.add(layers.Dense(units=32,activation=\"relu\"))\n",
    "model.add(layers.Dense(units=10,activation=tf.keras.activations.softmax))\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),loss=tf.keras.losses.categorical_crossentropy,metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 4s 4ms/sample - loss: 11.6697 - categorical_accuracy: 0.1020 - val_loss: 11.7159 - val_categorical_accuracy: 0.0750\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 359us/sample - loss: 11.6528 - categorical_accuracy: 0.0900 - val_loss: 11.7800 - val_categorical_accuracy: 0.0850\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 11.7654 - categorical_accuracy: 0.0880 - val_loss: 11.9987 - val_categorical_accuracy: 0.0850\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 75us/sample - loss: 12.1662 - categorical_accuracy: 0.0950 - val_loss: 12.6678 - val_categorical_accuracy: 0.1000\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 72us/sample - loss: 13.1737 - categorical_accuracy: 0.0970 - val_loss: 14.2066 - val_categorical_accuracy: 0.1000\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 77us/sample - loss: 15.4909 - categorical_accuracy: 0.1050 - val_loss: 17.7195 - val_categorical_accuracy: 0.1000\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 20.0840 - categorical_accuracy: 0.1060 - val_loss: 23.4775 - val_categorical_accuracy: 0.1000\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 76us/sample - loss: 26.5168 - categorical_accuracy: 0.1150 - val_loss: 30.8075 - val_categorical_accuracy: 0.0600\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 71us/sample - loss: 34.1017 - categorical_accuracy: 0.1150 - val_loss: 38.9699 - val_categorical_accuracy: 0.0850\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 66us/sample - loss: 43.0271 - categorical_accuracy: 0.1110 - val_loss: 49.2252 - val_categorical_accuracy: 0.0850\n",
      "[[7.60197004e-01 4.02073952e-01 2.69386378e-01 ... 9.79508029e-01\n",
      "  7.34197650e-01 6.52401954e-01]\n",
      " [9.94143321e-01 5.46313132e-01 7.94908561e-04 ... 8.68377945e-01\n",
      "  7.89133665e-01 5.21044368e-02]\n",
      " [5.44376387e-01 9.41288933e-01 7.03179705e-01 ... 4.90424863e-01\n",
      "  9.47108119e-01 9.72478409e-01]\n",
      " ...\n",
      " [4.43821483e-01 4.93489608e-01 3.47154003e-01 ... 5.27825652e-02\n",
      "  5.98385470e-01 1.64309881e-03]\n",
      " [4.13828535e-01 1.15561842e-01 2.98572540e-01 ... 9.89584466e-02\n",
      "  9.41843468e-03 1.76321632e-01]\n",
      " [7.62361264e-01 8.17117556e-01 7.39384647e-01 ... 4.34197919e-01\n",
      "  9.84371782e-01 8.60263577e-01]]\n",
      "[[0.39496086 0.83803633 0.56031243 ... 0.36228665 0.48423217 0.97342357]\n",
      " [0.04064867 0.24889672 0.67737434 ... 0.32726504 0.68490683 0.34642782]\n",
      " [0.07404467 0.06824793 0.48787251 ... 0.36563676 0.34573149 0.7198638 ]\n",
      " ...\n",
      " [0.84823509 0.79664119 0.36604668 ... 0.14294639 0.57414141 0.92949706]\n",
      " [0.04528139 0.92928718 0.41134882 ... 0.25156431 0.55547909 0.43478104]\n",
      " [0.45281043 0.96971883 0.8364102  ... 0.82499984 0.59472696 0.66518981]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "train_x=np.random.random((1000,72))\n",
    "train_y=np.random.random((1000,10))\n",
    "val_x=np.random.random((200,72))\n",
    "val_y=np.random.random((200,10))\n",
    "model.fit(train_x,train_y,epochs=10,batch_size=100,validation_data=(val_x,val_y))\n",
    "print(train_x)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (72,), types: tf.float64>\n"
     ]
    }
   ],
   "source": [
    "dataset=tf.data.Dataset.from_tensor_slices(train_x)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.random.random((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ts = tf.constant([[1, 2], [3, 4]])\n",
    "ds = tf.data.Dataset.from_tensor_slices(ts) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (2,), types: tf.int32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.array([1,2,3,4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
