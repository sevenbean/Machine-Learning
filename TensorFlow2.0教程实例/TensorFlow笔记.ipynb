{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "a=np.arange(0,20).reshape(4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将numpy中的数组转换为张量\n",
    "b=tf.convert_to_tensor(a,dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5), dtype=float32, numpy=\n",
       "array([[ 0.,  1.,  2.,  3.,  4.],\n",
       "       [ 5.,  6.,  7.,  8.,  9.],\n",
       "       [10., 11., 12., 13., 14.],\n",
       "       [15., 16., 17., 18., 19.]], dtype=float32)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[9 9 9]\n",
      " [9 9 9]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.ones((2,3))#创建一个全为0的张量\n",
    "b=tf.ones((2,3))#创建一个全为1的张量\n",
    "c=tf.fill((2,3),9)#创建一个为指定数的张量\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1.2585145   0.42963192  0.293192  ]\n",
      " [ 0.7900816   0.626118   -0.8049505 ]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-1.959253   -1.4141572   1.8928362 ]\n",
      " [ 1.1724001  -0.4450207   0.50816816]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 生成正态分部的随机数，均值默认为0，方差默认为1,mean为均值，stddev是方差\n",
    "a=tf.random.normal((2,3),mean=0,stddev=1.0)\n",
    "print(a)\n",
    "#生成截断式正态分布的随机数让其取值在（u-2*sigmoid,u+2*sigmoid）\n",
    "tb=tf.random.truncated_normal((2,3),mean=0,stddev=1.0)\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1.136795  2.8265448 4.1586647]\n",
      " [1.9512539 2.2380514 4.143064 ]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#生成均匀分布的随机数,minval为最小值，maxval为最大值\n",
    "tb=tf.random.uniform((2,3),minval=1.0,maxval=5.0)\n",
    "print(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2 34]\n",
      " [ 1  4  5]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant([[1,2,34],[1,4,5]])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 5.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([34.  5.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([37. 10.], shape=(2,), dtype=float32)\n",
      "tf.Tensor([ 1.   3.  19.5], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 将a的int类型转为float类型\n",
    "a=tf.cast(a,tf.float32)\n",
    "#在纵向求a的最小值，axis=0表示纵向，axis=1表示横向\n",
    "print(tf.reduce_min(a,axis=0))\n",
    "#在横向求a的最大值\n",
    "print(tf.reduce_max(a,axis=1))\n",
    "#在a的横向求和\n",
    "print(tf.reduce_sum(a,axis=1))\n",
    "#在a的纵向求平均值\n",
    "print(tf.reduce_mean(a,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[1. 1. 1.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[4. 4. 4.]], shape=(1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x1=tf.ones((1,3),dtype=tf.float32)\n",
    "x2=tf.fill((1,3),4.0,)\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[5. 5. 5.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[-3. -3. -3.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[4. 4. 4.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[0.25 0.25 0.25]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[64. 64. 64.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[16. 16. 16.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[2. 2. 2.]], shape=(1, 3), dtype=float32)\n",
      "tf.Tensor([[15.]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#加法\n",
    "print(tf.add(x1,x2))\n",
    "#减法\n",
    "print(tf.subtract(x1,x2))\n",
    "#乘法\n",
    "print(tf.multiply(x1,x2))\n",
    "#除法\n",
    "print(tf.divide(x1,x2))\n",
    "#几次方\n",
    "print(tf.pow(x2,3))\n",
    "#平方\n",
    "print(tf.square(x2))\n",
    "#开根号\n",
    "print(tf.sqrt(x2))\n",
    "#矩阵乘法\n",
    "x3=tf.fill((3,1),5.0)\n",
    "print(tf.matmul(x1,x3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1., 1., 1.], dtype=float32)>, <tf.Tensor: shape=(3,), dtype=float32, numpy=array([4., 4., 4.], dtype=float32)>)\n"
     ]
    }
   ],
   "source": [
    "#切分传入张量的第一维度，生成输入特征/标签对，构建数据集'\n",
    "features=tf.constant([12,23,56,1])\n",
    "labels=tf.constant([1,0,1,0])\n",
    "# data=tf.data.Dataset.from_tensor_slices((features,labels))\n",
    "data=tf.data.Dataset.from_tensor_slices((x1,x2))\n",
    "for i in data:\n",
    "    print(i)\n",
    "#print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 求张量的梯度\n",
    "with tf.GradientTape() as tp:\n",
    "    w=tf.Variable(3.0)\n",
    "    loss=tf.pow(w,2)\n",
    "grad=tp.gradient(loss,w)\n",
    "print(grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=3.0>\n"
     ]
    }
   ],
   "source": [
    "w=tf.Variable(tf.constant(3.0))\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 one\n",
      "1 two\n",
      "2 three\n"
     ]
    }
   ],
   "source": [
    "# enumerate可以遍历每个元素（如列表，元组，或者字符串），组合为：索引 元素,常在for循环中使用\n",
    "seq=[\"one\",\"two\",\"three\"]\n",
    "for i,element in enumerate(seq):\n",
    "    print(i,element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]], shape=(5, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "labels=tf.constant([1,2,3,4,5])\n",
    "output=tf.one_hot(labels,depth=6)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c: tf.Tensor([1 2 5 6 7 2], shape=(6,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#tensorflow的用法相当于Java中的三目运算符\n",
    "a=tf.constant([1,2,0,3,1,2])\n",
    "b=tf.constant([0,1,5,6,7,1])\n",
    "c=tf.where(tf.greater(a,b),a,b)#如果a>b，则返回a,如果a<b则返回b\n",
    "print(\"c:\",c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#生成一个[0,1)的随机数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.417022004702574\n",
      "[[7.20324493e-01 1.14374817e-04 3.02332573e-01]\n",
      " [1.46755891e-01 9.23385948e-02 1.86260211e-01]]\n"
     ]
    }
   ],
   "source": [
    "rdm=np.random.RandomState(seed=1)\n",
    "a=rdm.rand()\n",
    "b=rdm.rand(2,3)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.  1.  1.  1.  1.5 1.5 1.5 1.5 2.  2.  2.  2.  2.5 2.5 2.5 2.5]\n",
      "[2.  2.5 3.  3.5 2.  2.5 3.  3.5 2.  2.5 3.  3.5 2.  2.5 3.  3.5]\n",
      "[[1.  2. ]\n",
      " [1.  2.5]\n",
      " [1.  3. ]\n",
      " [1.  3.5]\n",
      " [1.5 2. ]\n",
      " [1.5 2.5]\n",
      " [1.5 3. ]\n",
      " [1.5 3.5]\n",
      " [2.  2. ]\n",
      " [2.  2.5]\n",
      " [2.  3. ]\n",
      " [2.  3.5]\n",
      " [2.5 2. ]\n",
      " [2.5 2.5]\n",
      " [2.5 3. ]\n",
      " [2.5 3.5]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x,y=np.mgrid[1:3:0.5,2:4:0.5]\n",
    "# 将多维数组拉直，变成一维的\n",
    "print(x.ravel())\n",
    "print(y.ravel())\n",
    "#使返回的间隔数值点配对\n",
    "print(np.c_[x.ravel(),y.ravel()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.5108256, shape=(), dtype=float32)\n",
      "tf.Tensor(0.22314353, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# 交叉熵损失函数\n",
    "loss1=tf.losses.categorical_crossentropy([1,0],[0.6,0.4])\n",
    "loss2=tf.losses.categorical_crossentropy([1,0],[0.8,0.2])\n",
    "print(loss1)\n",
    "print(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4]\n",
      " [4 5 6]]\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant([[1,2,4],[4,5,6]])\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([3 6 5], shape=(3,), dtype=int32)\n",
      "<tf.RaggedTensor [[97, 98, 99], [98, 106, 99, 99, 100, 101], [98, 106, 99, 100, 101]]>\n",
      "[[ 97  98  99   0   0   0]\n",
      " [ 98 106  99  99 100 101]\n",
      " [ 98 106  99 100 101   0]]\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant([\"abc\",\"bjccde\",\"bjcde\"])\n",
    "print(tf.strings.length(a))\n",
    "#长度不固定的张量表示为RaggedTensor.to_tensor转为普通的张量，填充的0在数字的后面\n",
    "print(tf.strings.unicode_decode(a,\"utf8\"))\n",
    "print(tf.strings.unicode_decode(a,\"utf8\").to_tensor().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4 0 0 0]\n",
      " [5 5 7 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [1 5 4 7 8 9]]\n"
     ]
    }
   ],
   "source": [
    "#长度不固定的张量\n",
    "a=tf.ragged.constant([[1,2,4],[5,5,7],[],[1,5,4,7,8,9]])\n",
    "print(a.to_tensor().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0]\n",
      " [0 0 0 2 0]\n",
      " [0 0 0 0 4]\n",
      " [0 0 0 0 0]]\n",
      "[[2 0 0 0]\n",
      " [1 0 0 0]\n",
      " [0 0 0 4]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "让固定的位置上填写指定的值,其中的indices里面必须按着顺序，\n",
    "否则在tf.sparse.to_dense就会报错\n",
    "\n",
    "'''\n",
    "a=tf.SparseTensor(indices=[[0,1],[1,3],[2,4]],\n",
    "                  values=[1,2,4],\n",
    "                  dense_shape=[4,5])\n",
    "print(tf.sparse.to_dense(a).numpy())\n",
    "b=tf.SparseTensor(indices=[[1,0],[0,0],[2,3]],\n",
    "                  values=[1,2,4],\n",
    "                  dense_shape=[3,4])\n",
    "#对indices进行了重新排序操作\n",
    "b=tf.sparse.reorder(b)\n",
    "print(tf.sparse.to_dense(b).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 4]\n",
      " [2 4 6]]\n",
      "[[ 1  2  4]\n",
      " [ 2  4 10]]\n",
      "[[1 2 4]\n",
      " [1 1 1]]\n",
      "[[2 4 8]\n",
      " [2 2 2]]\n"
     ]
    }
   ],
   "source": [
    "#变量\n",
    "a=tf.Variable([[1,2,4],[2,4,6]])\n",
    "print(a.numpy())\n",
    "#对a[1,2]赋值\n",
    "a[1,2].assign(10)\n",
    "print(a.numpy())\n",
    "#对a[1]进行赋值\n",
    "a[1].assign([1,1,1])\n",
    "print(a.numpy())\n",
    "#对a进行赋值\n",
    "a.assign(2*a)\n",
    "print(a.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "c=tf.Variable(6)\n",
    "print(c.numpy())\n",
    "c.assign(10)\n",
    "print(c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[17]\n",
      " [32]], shape=(2, 1), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant([[1,2,4],[4,5,6]])\n",
    "b=tf.constant([[1],[2],[3]])\n",
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
